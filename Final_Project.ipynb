{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/liufamily/.cache/kagglehub/datasets/andrewsundberg/college-basketball-dataset/versions/7\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"andrewsundberg/college-basketball-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEAM</th>\n",
       "      <th>CONF</th>\n",
       "      <th>G</th>\n",
       "      <th>W</th>\n",
       "      <th>ADJOE</th>\n",
       "      <th>ADJDE</th>\n",
       "      <th>BARTHAG</th>\n",
       "      <th>EFG_O</th>\n",
       "      <th>EFG_D</th>\n",
       "      <th>TOR</th>\n",
       "      <th>...</th>\n",
       "      <th>FTRD</th>\n",
       "      <th>2P_O</th>\n",
       "      <th>2P_D</th>\n",
       "      <th>3P_O</th>\n",
       "      <th>3P_D</th>\n",
       "      <th>ADJ_T</th>\n",
       "      <th>WAB</th>\n",
       "      <th>POSTSEASON</th>\n",
       "      <th>SEED</th>\n",
       "      <th>YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>ACC</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>123.3</td>\n",
       "      <td>94.9</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>52.6</td>\n",
       "      <td>48.1</td>\n",
       "      <td>15.4</td>\n",
       "      <td>...</td>\n",
       "      <td>30.4</td>\n",
       "      <td>53.9</td>\n",
       "      <td>44.6</td>\n",
       "      <td>32.7</td>\n",
       "      <td>36.2</td>\n",
       "      <td>71.7</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2ND</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>B10</td>\n",
       "      <td>40</td>\n",
       "      <td>36</td>\n",
       "      <td>129.1</td>\n",
       "      <td>93.6</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>54.8</td>\n",
       "      <td>47.7</td>\n",
       "      <td>12.4</td>\n",
       "      <td>...</td>\n",
       "      <td>22.4</td>\n",
       "      <td>54.8</td>\n",
       "      <td>44.7</td>\n",
       "      <td>36.5</td>\n",
       "      <td>37.5</td>\n",
       "      <td>59.3</td>\n",
       "      <td>11.3</td>\n",
       "      <td>2ND</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>B10</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>114.4</td>\n",
       "      <td>90.4</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>53.9</td>\n",
       "      <td>47.7</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54.7</td>\n",
       "      <td>46.8</td>\n",
       "      <td>35.2</td>\n",
       "      <td>33.2</td>\n",
       "      <td>65.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2ND</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Texas Tech</td>\n",
       "      <td>B12</td>\n",
       "      <td>38</td>\n",
       "      <td>31</td>\n",
       "      <td>115.2</td>\n",
       "      <td>85.2</td>\n",
       "      <td>0.9696</td>\n",
       "      <td>53.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>...</td>\n",
       "      <td>36.6</td>\n",
       "      <td>52.8</td>\n",
       "      <td>41.9</td>\n",
       "      <td>36.5</td>\n",
       "      <td>29.7</td>\n",
       "      <td>67.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2ND</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gonzaga</td>\n",
       "      <td>WCC</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>117.8</td>\n",
       "      <td>86.3</td>\n",
       "      <td>0.9728</td>\n",
       "      <td>56.6</td>\n",
       "      <td>41.1</td>\n",
       "      <td>16.2</td>\n",
       "      <td>...</td>\n",
       "      <td>26.9</td>\n",
       "      <td>56.3</td>\n",
       "      <td>40.0</td>\n",
       "      <td>38.2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>71.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2ND</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3518</th>\n",
       "      <td>Toledo</td>\n",
       "      <td>MAC</td>\n",
       "      <td>34</td>\n",
       "      <td>27</td>\n",
       "      <td>119.9</td>\n",
       "      <td>109.6</td>\n",
       "      <td>0.7369</td>\n",
       "      <td>56.3</td>\n",
       "      <td>52.9</td>\n",
       "      <td>13.6</td>\n",
       "      <td>...</td>\n",
       "      <td>27.5</td>\n",
       "      <td>54.6</td>\n",
       "      <td>52.1</td>\n",
       "      <td>39.7</td>\n",
       "      <td>36.1</td>\n",
       "      <td>69.5</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3519</th>\n",
       "      <td>Liberty</td>\n",
       "      <td>ASun</td>\n",
       "      <td>33</td>\n",
       "      <td>27</td>\n",
       "      <td>111.4</td>\n",
       "      <td>97.3</td>\n",
       "      <td>0.8246</td>\n",
       "      <td>55.5</td>\n",
       "      <td>49.3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.8</td>\n",
       "      <td>56.4</td>\n",
       "      <td>48.6</td>\n",
       "      <td>36.4</td>\n",
       "      <td>33.6</td>\n",
       "      <td>64.4</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3520</th>\n",
       "      <td>Utah Valley</td>\n",
       "      <td>WAC</td>\n",
       "      <td>34</td>\n",
       "      <td>28</td>\n",
       "      <td>107.1</td>\n",
       "      <td>94.6</td>\n",
       "      <td>0.8065</td>\n",
       "      <td>51.7</td>\n",
       "      <td>44.0</td>\n",
       "      <td>19.3</td>\n",
       "      <td>...</td>\n",
       "      <td>28.7</td>\n",
       "      <td>52.5</td>\n",
       "      <td>42.8</td>\n",
       "      <td>33.4</td>\n",
       "      <td>31.1</td>\n",
       "      <td>69.8</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3521</th>\n",
       "      <td>UAB</td>\n",
       "      <td>CUSA</td>\n",
       "      <td>38</td>\n",
       "      <td>29</td>\n",
       "      <td>112.4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.8453</td>\n",
       "      <td>50.3</td>\n",
       "      <td>47.3</td>\n",
       "      <td>17.3</td>\n",
       "      <td>...</td>\n",
       "      <td>28.9</td>\n",
       "      <td>48.8</td>\n",
       "      <td>47.2</td>\n",
       "      <td>35.6</td>\n",
       "      <td>31.6</td>\n",
       "      <td>70.7</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3522</th>\n",
       "      <td>North Texas</td>\n",
       "      <td>CUSA</td>\n",
       "      <td>36</td>\n",
       "      <td>31</td>\n",
       "      <td>110.0</td>\n",
       "      <td>93.8</td>\n",
       "      <td>0.8622</td>\n",
       "      <td>51.2</td>\n",
       "      <td>44.5</td>\n",
       "      <td>19.8</td>\n",
       "      <td>...</td>\n",
       "      <td>40.2</td>\n",
       "      <td>49.6</td>\n",
       "      <td>44.2</td>\n",
       "      <td>35.7</td>\n",
       "      <td>30.1</td>\n",
       "      <td>58.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3523 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                TEAM  CONF   G   W  ADJOE  ADJDE  BARTHAG  EFG_O  EFG_D   TOR  \\\n",
       "0     North Carolina   ACC  40  33  123.3   94.9   0.9531   52.6   48.1  15.4   \n",
       "1          Wisconsin   B10  40  36  129.1   93.6   0.9758   54.8   47.7  12.4   \n",
       "2           Michigan   B10  40  33  114.4   90.4   0.9375   53.9   47.7  14.0   \n",
       "3         Texas Tech   B12  38  31  115.2   85.2   0.9696   53.5   43.0  17.7   \n",
       "4            Gonzaga   WCC  39  37  117.8   86.3   0.9728   56.6   41.1  16.2   \n",
       "...              ...   ...  ..  ..    ...    ...      ...    ...    ...   ...   \n",
       "3518          Toledo   MAC  34  27  119.9  109.6   0.7369   56.3   52.9  13.6   \n",
       "3519         Liberty  ASun  33  27  111.4   97.3   0.8246   55.5   49.3  16.0   \n",
       "3520     Utah Valley   WAC  34  28  107.1   94.6   0.8065   51.7   44.0  19.3   \n",
       "3521             UAB  CUSA  38  29  112.4   97.0   0.8453   50.3   47.3  17.3   \n",
       "3522     North Texas  CUSA  36  31  110.0   93.8   0.8622   51.2   44.5  19.8   \n",
       "\n",
       "      ...  FTRD  2P_O  2P_D  3P_O  3P_D  ADJ_T   WAB  POSTSEASON  SEED  YEAR  \n",
       "0     ...  30.4  53.9  44.6  32.7  36.2   71.7   8.6         2ND   1.0  2016  \n",
       "1     ...  22.4  54.8  44.7  36.5  37.5   59.3  11.3         2ND   1.0  2015  \n",
       "2     ...  30.0  54.7  46.8  35.2  33.2   65.9   6.9         2ND   3.0  2018  \n",
       "3     ...  36.6  52.8  41.9  36.5  29.7   67.5   7.0         2ND   3.0  2019  \n",
       "4     ...  26.9  56.3  40.0  38.2  29.0   71.5   7.7         2ND   1.0  2017  \n",
       "...   ...   ...   ...   ...   ...   ...    ...   ...         ...   ...   ...  \n",
       "3518  ...  27.5  54.6  52.1  39.7  36.1   69.5  -1.2         NaN   NaN  2023  \n",
       "3519  ...  27.8  56.4  48.6  36.4  33.6   64.4  -2.0         NaN   NaN  2023  \n",
       "3520  ...  28.7  52.5  42.8  33.4  31.1   69.8  -0.3         NaN   NaN  2023  \n",
       "3521  ...  28.9  48.8  47.2  35.6  31.6   70.7  -0.5         NaN   NaN  2023  \n",
       "3522  ...  40.2  49.6  44.2  35.7  30.1   58.7   1.1         NaN   NaN  2023  \n",
       "\n",
       "[3523 rows x 24 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('cbb.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q0/hn6y49dn3qlbbv0j58dc42tm0000gn/T/ipykernel_39806/2438171600.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data_cleaned['POSTSEASON'] = data_cleaned[\"POSTSEASON\"].replace(value_mapping)\n",
      "/var/folders/q0/hn6y49dn3qlbbv0j58dc42tm0000gn/T/ipykernel_39806/2438171600.py:15: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data_cleaned2['POSTSEASON'] = data_cleaned2[\"POSTSEASON\"].replace(value_mapping)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADJOE</th>\n",
       "      <th>ADJDE</th>\n",
       "      <th>BARTHAG</th>\n",
       "      <th>EFG_O</th>\n",
       "      <th>EFG_D</th>\n",
       "      <th>TOR</th>\n",
       "      <th>TORD</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>FTR</th>\n",
       "      <th>...</th>\n",
       "      <th>YEAR_2013</th>\n",
       "      <th>YEAR_2014</th>\n",
       "      <th>YEAR_2015</th>\n",
       "      <th>YEAR_2016</th>\n",
       "      <th>YEAR_2017</th>\n",
       "      <th>YEAR_2018</th>\n",
       "      <th>YEAR_2019</th>\n",
       "      <th>YEAR_2021</th>\n",
       "      <th>YEAR_2022</th>\n",
       "      <th>YEAR_2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.3</td>\n",
       "      <td>94.9</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>52.6</td>\n",
       "      <td>48.1</td>\n",
       "      <td>15.4</td>\n",
       "      <td>18.2</td>\n",
       "      <td>40.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129.1</td>\n",
       "      <td>93.6</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>54.8</td>\n",
       "      <td>47.7</td>\n",
       "      <td>12.4</td>\n",
       "      <td>15.8</td>\n",
       "      <td>32.1</td>\n",
       "      <td>23.7</td>\n",
       "      <td>36.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>114.4</td>\n",
       "      <td>90.4</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>53.9</td>\n",
       "      <td>47.7</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>25.5</td>\n",
       "      <td>24.9</td>\n",
       "      <td>30.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115.2</td>\n",
       "      <td>85.2</td>\n",
       "      <td>0.9696</td>\n",
       "      <td>53.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>22.8</td>\n",
       "      <td>27.4</td>\n",
       "      <td>28.7</td>\n",
       "      <td>32.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117.8</td>\n",
       "      <td>86.3</td>\n",
       "      <td>0.9728</td>\n",
       "      <td>56.6</td>\n",
       "      <td>41.1</td>\n",
       "      <td>16.2</td>\n",
       "      <td>17.1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3518</th>\n",
       "      <td>119.9</td>\n",
       "      <td>109.6</td>\n",
       "      <td>0.7369</td>\n",
       "      <td>56.3</td>\n",
       "      <td>52.9</td>\n",
       "      <td>13.6</td>\n",
       "      <td>18.3</td>\n",
       "      <td>29.8</td>\n",
       "      <td>30.9</td>\n",
       "      <td>34.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3519</th>\n",
       "      <td>111.4</td>\n",
       "      <td>97.3</td>\n",
       "      <td>0.8246</td>\n",
       "      <td>55.5</td>\n",
       "      <td>49.3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>25.3</td>\n",
       "      <td>20.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3520</th>\n",
       "      <td>107.1</td>\n",
       "      <td>94.6</td>\n",
       "      <td>0.8065</td>\n",
       "      <td>51.7</td>\n",
       "      <td>44.0</td>\n",
       "      <td>19.3</td>\n",
       "      <td>16.3</td>\n",
       "      <td>28.9</td>\n",
       "      <td>29.1</td>\n",
       "      <td>35.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3521</th>\n",
       "      <td>112.4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.8453</td>\n",
       "      <td>50.3</td>\n",
       "      <td>47.3</td>\n",
       "      <td>17.3</td>\n",
       "      <td>19.3</td>\n",
       "      <td>35.8</td>\n",
       "      <td>29.3</td>\n",
       "      <td>35.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3522</th>\n",
       "      <td>110.0</td>\n",
       "      <td>93.8</td>\n",
       "      <td>0.8622</td>\n",
       "      <td>51.2</td>\n",
       "      <td>44.5</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.9</td>\n",
       "      <td>33.4</td>\n",
       "      <td>28.6</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3523 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ADJOE  ADJDE  BARTHAG  EFG_O  EFG_D   TOR  TORD   ORB   DRB   FTR  ...  \\\n",
       "0     123.3   94.9   0.9531   52.6   48.1  15.4  18.2  40.7  30.0  32.3  ...   \n",
       "1     129.1   93.6   0.9758   54.8   47.7  12.4  15.8  32.1  23.7  36.2  ...   \n",
       "2     114.4   90.4   0.9375   53.9   47.7  14.0  19.5  25.5  24.9  30.7  ...   \n",
       "3     115.2   85.2   0.9696   53.5   43.0  17.7  22.8  27.4  28.7  32.9  ...   \n",
       "4     117.8   86.3   0.9728   56.6   41.1  16.2  17.1  30.0  26.2  39.0  ...   \n",
       "...     ...    ...      ...    ...    ...   ...   ...   ...   ...   ...  ...   \n",
       "3518  119.9  109.6   0.7369   56.3   52.9  13.6  18.3  29.8  30.9  34.4  ...   \n",
       "3519  111.4   97.3   0.8246   55.5   49.3  16.0  18.9  25.3  20.2  26.2  ...   \n",
       "3520  107.1   94.6   0.8065   51.7   44.0  19.3  16.3  28.9  29.1  35.6  ...   \n",
       "3521  112.4   97.0   0.8453   50.3   47.3  17.3  19.3  35.8  29.3  35.7  ...   \n",
       "3522  110.0   93.8   0.8622   51.2   44.5  19.8  19.9  33.4  28.6  31.0  ...   \n",
       "\n",
       "      YEAR_2013  YEAR_2014  YEAR_2015  YEAR_2016  YEAR_2017  YEAR_2018  \\\n",
       "0           0.0        0.0        0.0        1.0        0.0        0.0   \n",
       "1           0.0        0.0        1.0        0.0        0.0        0.0   \n",
       "2           0.0        0.0        0.0        0.0        0.0        1.0   \n",
       "3           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4           0.0        0.0        0.0        0.0        1.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "3518        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3519        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3520        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3521        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3522        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "      YEAR_2019  YEAR_2021  YEAR_2022  YEAR_2023  \n",
       "0           0.0        0.0        0.0        0.0  \n",
       "1           0.0        0.0        0.0        0.0  \n",
       "2           0.0        0.0        0.0        0.0  \n",
       "3           1.0        0.0        0.0        0.0  \n",
       "4           0.0        0.0        0.0        0.0  \n",
       "...         ...        ...        ...        ...  \n",
       "3518        0.0        0.0        0.0        1.0  \n",
       "3519        0.0        0.0        0.0        1.0  \n",
       "3520        0.0        0.0        0.0        1.0  \n",
       "3521        0.0        0.0        0.0        1.0  \n",
       "3522        0.0        0.0        0.0        1.0  \n",
       "\n",
       "[3523 rows x 64 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_mapping = {\n",
    "    np.nan: 0,\n",
    "    \"R68\": 1,\n",
    "    \"R64\": 2,\n",
    "    \"R32\": 3,\n",
    "    \"S16\": 4,\n",
    "    \"E8\": 5,\n",
    "    \"F4\": 6,\n",
    "    \"2ND\": 7,\n",
    "    \"Champions\": 8\n",
    "}\n",
    "data_cleaned = data.copy()\n",
    "data_cleaned2 = data_cleaned.drop(['TEAM', 'G', 'W', 'CONF', 'YEAR', 'WAB'], axis=1)\n",
    "data_cleaned['POSTSEASON'] = data_cleaned[\"POSTSEASON\"].replace(value_mapping)\n",
    "data_cleaned2['POSTSEASON'] = data_cleaned2[\"POSTSEASON\"].replace(value_mapping)\n",
    "\n",
    "data_cleaned = pd.get_dummies(data_cleaned, columns=['CONF'])\n",
    "data_cleaned = pd.get_dummies(data_cleaned, columns=['YEAR'])\n",
    "data_cleaned = data_cleaned.drop(['TEAM', 'G', 'W'], axis=1)\n",
    "data_cleaned = data_cleaned.astype(float)\n",
    "data_cleaned2 = data_cleaned2.astype(float)\n",
    "data_cleaned2.fillna(0.0, inplace=True)\n",
    "data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned_no_seed = data_cleaned.drop('SEED', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3523, 63)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_array = data_cleaned.drop(\"POSTSEASON\", axis=1).to_numpy()\n",
    "X_data_array_no_seed = data_cleaned_no_seed.drop(\"POSTSEASON\", axis=1).to_numpy()\n",
    "X_data_array2 = data_cleaned2.drop(\"POSTSEASON\", axis=1).to_numpy()\n",
    "X_data_array = np.nan_to_num(X_data_array) \n",
    "X_data_array_no_seed = np.nan_to_num(X_data_array_no_seed) \n",
    "X_data_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7., 7., 7., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels_array = data_cleaned['POSTSEASON'].to_numpy()\n",
    "y_labels_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data_array, y_labels_array, test_size=0.2)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_data_array2, y_labels_array, test_size=0.2)\n",
    "X_train_no_seed, X_test_no_seed, y_train_no_seed, y_test_no_seed = train_test_split(X_data_array, y_labels_array, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train, num_classes=9)\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train_no_seed, num_classes=9)\n",
    "#class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_dict = {0.0: 0.01, 1.0: 2.0, 2.0: 2.0, 3.0: 4.0, 4.0: 8.0, 5.0: 16.0, 6.0: 32.0, 7.0: 64.0, 8.0: 128.0}\n",
    "#class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(63,)),  # Input layer with 4 features\n",
    "    layers.Dense(9, activation='softmax')  # Output layer with 3 classes (Softmax output)\n",
    "])\n",
    "model_no_seed = models.Sequential([\n",
    "    layers.Input(shape=(62,)),  # Input layer with 4 features\n",
    "    layers.Dense(9, activation='softmax')  # Output layer with 3 classes (Softmax output)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889us/step - accuracy: 0.0204 - loss: 36.7114 \n",
      "Epoch 2/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.0198 - loss: 8.6586\n",
      "Epoch 3/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0239 - loss: 8.0312\n",
      "Epoch 4/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0263 - loss: 6.9308\n",
      "Epoch 5/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0295 - loss: 6.5748\n",
      "Epoch 6/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.0195 - loss: 5.7855\n",
      "Epoch 7/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0239 - loss: 5.2158  \n",
      "Epoch 8/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0253 - loss: 5.6326\n",
      "Epoch 9/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.0278 - loss: 4.5953\n",
      "Epoch 10/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.0143 - loss: 5.3486\n",
      "Epoch 11/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0255 - loss: 4.7458  \n",
      "Epoch 12/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0214 - loss: 4.4416\n",
      "Epoch 13/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0184 - loss: 5.1631\n",
      "Epoch 14/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.0449 - loss: 3.8067\n",
      "Epoch 15/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.0281 - loss: 4.3524\n",
      "Epoch 16/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.0314 - loss: 4.2068\n",
      "Epoch 17/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - accuracy: 0.0293 - loss: 4.5802\n",
      "Epoch 18/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.0334 - loss: 4.9057\n",
      "Epoch 19/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 0.0388 - loss: 4.1216\n",
      "Epoch 20/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.0240 - loss: 4.5269\n",
      "Epoch 21/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.0335 - loss: 3.2948\n",
      "Epoch 22/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0303 - loss: 4.1375\n",
      "Epoch 23/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 0.0390 - loss: 3.0856\n",
      "Epoch 24/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.0246 - loss: 3.4685\n",
      "Epoch 25/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.0340 - loss: 3.2122\n",
      "Epoch 26/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.0288 - loss: 3.5348\n",
      "Epoch 27/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - accuracy: 0.0373 - loss: 3.3103\n",
      "Epoch 28/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.0346 - loss: 3.1610\n",
      "Epoch 29/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - accuracy: 0.0367 - loss: 3.0621\n",
      "Epoch 30/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.0352 - loss: 3.4244\n",
      "Epoch 31/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.0376 - loss: 3.3744\n",
      "Epoch 32/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.0275 - loss: 3.5622\n",
      "Epoch 33/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - accuracy: 0.0334 - loss: 3.2336\n",
      "Epoch 34/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - accuracy: 0.0333 - loss: 2.8523\n",
      "Epoch 35/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - accuracy: 0.0340 - loss: 2.7491\n",
      "Epoch 36/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.0327 - loss: 2.8519\n",
      "Epoch 37/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.0462 - loss: 2.4023\n",
      "Epoch 38/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 0.0438 - loss: 3.1637\n",
      "Epoch 39/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 0.0359 - loss: 3.0286\n",
      "Epoch 40/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.0295 - loss: 2.8663\n",
      "Epoch 41/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - accuracy: 0.0486 - loss: 3.2362\n",
      "Epoch 42/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.0438 - loss: 2.6777\n",
      "Epoch 43/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.0402 - loss: 2.6215\n",
      "Epoch 44/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - accuracy: 0.0390 - loss: 2.9737\n",
      "Epoch 45/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 0.0421 - loss: 3.5240\n",
      "Epoch 46/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - accuracy: 0.0467 - loss: 2.7000\n",
      "Epoch 47/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.0429 - loss: 2.9709\n",
      "Epoch 48/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - accuracy: 0.0385 - loss: 3.1413\n",
      "Epoch 49/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.0412 - loss: 2.8516\n",
      "Epoch 50/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - accuracy: 0.0376 - loss: 2.3391\n",
      "Epoch 51/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.0492 - loss: 2.5127\n",
      "Epoch 52/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.0379 - loss: 2.6717\n",
      "Epoch 53/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.0482 - loss: 2.5170\n",
      "Epoch 54/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - accuracy: 0.0371 - loss: 3.0574\n",
      "Epoch 55/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.0430 - loss: 2.6403\n",
      "Epoch 56/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.0440 - loss: 2.5336\n",
      "Epoch 57/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.0478 - loss: 2.8575\n",
      "Epoch 58/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.0468 - loss: 2.7249\n",
      "Epoch 59/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.0385 - loss: 2.8977\n",
      "Epoch 60/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.0577 - loss: 2.6244\n",
      "Epoch 61/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.0477 - loss: 3.2532\n",
      "Epoch 62/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - accuracy: 0.0507 - loss: 2.4085\n",
      "Epoch 63/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.0450 - loss: 2.8711\n",
      "Epoch 64/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - accuracy: 0.0374 - loss: 2.5219\n",
      "Epoch 65/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - accuracy: 0.0403 - loss: 2.7956\n",
      "Epoch 66/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.0553 - loss: 2.1575\n",
      "Epoch 67/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.0505 - loss: 2.6060\n",
      "Epoch 68/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.0438 - loss: 3.0177\n",
      "Epoch 69/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - accuracy: 0.0473 - loss: 2.3797\n",
      "Epoch 70/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.0416 - loss: 2.7034\n",
      "Epoch 71/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.0551 - loss: 2.4249\n",
      "Epoch 72/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.0412 - loss: 2.6790\n",
      "Epoch 73/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0445 - loss: 2.5398  \n",
      "Epoch 74/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0522 - loss: 2.3750\n",
      "Epoch 75/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0502 - loss: 2.3148\n",
      "Epoch 76/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.0467 - loss: 2.4441\n",
      "Epoch 77/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.0603 - loss: 2.3488\n",
      "Epoch 78/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - accuracy: 0.0535 - loss: 2.5736\n",
      "Epoch 79/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 0.0431 - loss: 2.3531\n",
      "Epoch 80/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.0484 - loss: 3.2534\n",
      "Epoch 81/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.0473 - loss: 2.6864\n",
      "Epoch 82/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.0516 - loss: 2.9105\n",
      "Epoch 83/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.0513 - loss: 2.4224\n",
      "Epoch 84/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.0467 - loss: 2.5946\n",
      "Epoch 85/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - accuracy: 0.0532 - loss: 2.2896\n",
      "Epoch 86/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.0471 - loss: 2.0114\n",
      "Epoch 87/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - accuracy: 0.0448 - loss: 2.4667\n",
      "Epoch 88/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.0484 - loss: 2.8776\n",
      "Epoch 89/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - accuracy: 0.0456 - loss: 2.1806\n",
      "Epoch 90/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - accuracy: 0.0411 - loss: 3.0626\n",
      "Epoch 91/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.0522 - loss: 2.0682\n",
      "Epoch 92/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0537 - loss: 2.1443\n",
      "Epoch 93/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.0496 - loss: 2.3512\n",
      "Epoch 94/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.0498 - loss: 2.1341\n",
      "Epoch 95/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - accuracy: 0.0447 - loss: 3.0983\n",
      "Epoch 96/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.0499 - loss: 2.4780\n",
      "Epoch 97/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.0516 - loss: 2.1192\n",
      "Epoch 98/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - accuracy: 0.0445 - loss: 2.2700\n",
      "Epoch 99/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 0.0570 - loss: 2.0288\n",
      "Epoch 100/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.0509 - loss: 2.0466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a3658610>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train_one_hot, epochs=100, batch_size=16, class_weight=class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.00160134 0.04482429 0.00434229 0.04837518 0.01486966 0.0167531\n",
      "  0.00679003 0.59832215 0.26412192]], shape=(1, 9), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "single_sample = tf.expand_dims(X_train[0], axis=0)\n",
    "\n",
    "# Pass it through the model\n",
    "output = model(single_sample)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.26285714 0.99       0.02205882 ... 0.6        0.32773109 0.        ]\n",
      " [0.66095238 0.505      0.69158497 ... 0.49411765 0.6092437  0.        ]\n",
      " [0.50666667 0.42       0.57608252 ... 0.40588235 0.40336134 0.        ]\n",
      " ...\n",
      " [0.46857143 0.41       0.52992239 ... 0.21176471 0.36134454 0.        ]\n",
      " [0.3047619  0.635      0.12520425 ... 0.65294118 0.30672269 0.        ]\n",
      " [0.71238095 0.295      0.89511846 ... 0.37058824 0.40336134 0.5625    ]]\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "y_train_one_hot2 = tf.keras.utils.to_categorical(y_train2, num_classes=9)\n",
    "\n",
    "X_train_scaled2 = scaler.fit_transform(X_train2)\n",
    "X_test_scaled2 = scaler.transform(X_test2)\n",
    "\n",
    "print(X_train_scaled2)\n",
    "print(y_train_one_hot2)\n",
    "\n",
    "model2 = models.Sequential([\n",
    "    layers.Input(shape=(17,)),  # Input layer with 4 features\n",
    "    layers.Dense(9, activation='softmax')  # Output layer with 3 classes (Softmax output)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - accuracy: 0.0657 - loss: 2.7274\n",
      "Epoch 2/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.0650 - loss: 2.5679\n",
      "Epoch 3/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.0845 - loss: 2.0707 \n",
      "Epoch 4/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.0759 - loss: 2.1032\n",
      "Epoch 5/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - accuracy: 0.2227 - loss: 2.5563\n",
      "Epoch 6/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.4083 - loss: 2.2683\n",
      "Epoch 7/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.5596 - loss: 2.2440\n",
      "Epoch 8/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.6201 - loss: 2.5823\n",
      "Epoch 9/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.6346 - loss: 2.2105\n",
      "Epoch 10/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.7149 - loss: 2.1724\n",
      "Epoch 11/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.6472 - loss: 2.6756\n",
      "Epoch 12/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.7520 - loss: 2.0890\n",
      "Epoch 13/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 0.7484 - loss: 1.9768\n",
      "Epoch 14/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.7839 - loss: 1.9215\n",
      "Epoch 15/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.7160 - loss: 2.1967\n",
      "Epoch 16/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 0.7447 - loss: 2.3259\n",
      "Epoch 17/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.7496 - loss: 2.1051\n",
      "Epoch 18/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.7881 - loss: 1.8615\n",
      "Epoch 19/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.7360 - loss: 2.4186\n",
      "Epoch 20/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - accuracy: 0.7881 - loss: 2.3084\n",
      "Epoch 21/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - accuracy: 0.7893 - loss: 2.1762\n",
      "Epoch 22/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - accuracy: 0.8036 - loss: 2.0439\n",
      "Epoch 23/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.8014 - loss: 2.2447\n",
      "Epoch 24/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - accuracy: 0.7908 - loss: 2.2792\n",
      "Epoch 25/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.8121 - loss: 1.9348\n",
      "Epoch 26/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - accuracy: 0.7988 - loss: 2.1220\n",
      "Epoch 27/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.8215 - loss: 1.8263\n",
      "Epoch 28/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.8140 - loss: 1.9891\n",
      "Epoch 29/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.8110 - loss: 2.1429\n",
      "Epoch 30/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.8403 - loss: 1.8582\n",
      "Epoch 31/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.8024 - loss: 2.1330\n",
      "Epoch 32/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.8464 - loss: 2.1098\n",
      "Epoch 33/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.8389 - loss: 1.9850\n",
      "Epoch 34/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.8277 - loss: 1.8888\n",
      "Epoch 35/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.8518 - loss: 1.8316\n",
      "Epoch 36/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.8474 - loss: 1.9885\n",
      "Epoch 37/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.8281 - loss: 1.9667\n",
      "Epoch 38/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.8318 - loss: 1.9860\n",
      "Epoch 39/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.8251 - loss: 2.1122\n",
      "Epoch 40/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.8517 - loss: 1.8761\n",
      "Epoch 41/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.8383 - loss: 1.8472\n",
      "Epoch 42/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.8551 - loss: 2.2381\n",
      "Epoch 43/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8560 - loss: 1.7656  \n",
      "Epoch 44/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.8568 - loss: 1.9125\n",
      "Epoch 45/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.8373 - loss: 1.8442\n",
      "Epoch 46/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - accuracy: 0.8408 - loss: 2.0915\n",
      "Epoch 47/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.8480 - loss: 1.9285\n",
      "Epoch 48/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8619 - loss: 1.8067\n",
      "Epoch 49/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.8430 - loss: 1.5918\n",
      "Epoch 50/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.8560 - loss: 1.9122\n",
      "Epoch 51/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.8448 - loss: 2.0175\n",
      "Epoch 52/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - accuracy: 0.8585 - loss: 1.8860\n",
      "Epoch 53/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.8474 - loss: 2.0639\n",
      "Epoch 54/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.8687 - loss: 1.7421\n",
      "Epoch 55/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.8539 - loss: 2.1173\n",
      "Epoch 56/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.8727 - loss: 2.0526\n",
      "Epoch 57/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.8621 - loss: 1.8201\n",
      "Epoch 58/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - accuracy: 0.8684 - loss: 1.8359\n",
      "Epoch 59/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.8675 - loss: 1.7844\n",
      "Epoch 60/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.8689 - loss: 1.7629\n",
      "Epoch 61/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.8657 - loss: 1.6567\n",
      "Epoch 62/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.8623 - loss: 1.9533\n",
      "Epoch 63/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.8850 - loss: 1.6476\n",
      "Epoch 64/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.8675 - loss: 1.9137\n",
      "Epoch 65/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.8733 - loss: 1.6476\n",
      "Epoch 66/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - accuracy: 0.8672 - loss: 1.9038\n",
      "Epoch 67/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.8742 - loss: 1.8968\n",
      "Epoch 68/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.8688 - loss: 1.9967\n",
      "Epoch 69/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 0.8770 - loss: 1.7258\n",
      "Epoch 70/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.8710 - loss: 1.8582\n",
      "Epoch 71/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.8678 - loss: 1.8883\n",
      "Epoch 72/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - accuracy: 0.8910 - loss: 1.6602\n",
      "Epoch 73/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - accuracy: 0.8627 - loss: 2.0639\n",
      "Epoch 74/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.8660 - loss: 1.9554\n",
      "Epoch 75/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.8690 - loss: 1.8049\n",
      "Epoch 76/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.8770 - loss: 1.7844\n",
      "Epoch 77/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.8880 - loss: 1.8603\n",
      "Epoch 78/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - accuracy: 0.8727 - loss: 1.6902\n",
      "Epoch 79/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - accuracy: 0.8851 - loss: 1.8855\n",
      "Epoch 80/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 0.8762 - loss: 1.9899\n",
      "Epoch 81/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.8755 - loss: 1.7218\n",
      "Epoch 82/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.8664 - loss: 1.9470\n",
      "Epoch 83/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.8766 - loss: 1.7455\n",
      "Epoch 84/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - accuracy: 0.8723 - loss: 1.7365\n",
      "Epoch 85/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.8774 - loss: 1.9581\n",
      "Epoch 86/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.8733 - loss: 1.6747\n",
      "Epoch 87/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - accuracy: 0.8779 - loss: 2.1289\n",
      "Epoch 88/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.8649 - loss: 1.9835\n",
      "Epoch 89/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.8830 - loss: 1.9617\n",
      "Epoch 90/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.8762 - loss: 1.7981\n",
      "Epoch 91/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.8703 - loss: 1.7136\n",
      "Epoch 92/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.8896 - loss: 1.6211\n",
      "Epoch 93/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.8822 - loss: 1.7279\n",
      "Epoch 94/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - accuracy: 0.8759 - loss: 1.8425\n",
      "Epoch 95/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - accuracy: 0.8801 - loss: 1.8775\n",
      "Epoch 96/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8879 - loss: 1.8253  \n",
      "Epoch 97/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8836 - loss: 2.0680\n",
      "Epoch 98/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8843 - loss: 1.7997\n",
      "Epoch 99/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.8816 - loss: 2.0924\n",
      "Epoch 100/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.8988 - loss: 1.5172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a7dd7610>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model2.compile(optimizer=optimizer, \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model2.fit(X_train_scaled2, y_train_one_hot2, epochs=100, batch_size=16, class_weight=class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(1, 9), dtype=float32)\n",
      "[<Variable path=sequential_55/dense_65/kernel, shape=(17, 9), dtype=float32, value=[[-8.9030371e+00 -1.7935888e+00 -3.6345479e+00 -2.3542562e+00\n",
      "  -1.1096926e+00 -9.1230184e-01  8.0325407e-01  1.1981736e+00\n",
      "   8.4165329e-01]\n",
      " [ 1.9435766e+01  5.3904181e+00  4.2724872e+00  4.4735050e+00\n",
      "   1.8391510e+00  5.3516233e-01  6.2289268e-01 -4.6955695e+00\n",
      "  -2.2326274e+00]\n",
      " [-6.0786071e+00 -5.1233664e+00 -2.5812275e+00 -2.6132898e-02\n",
      "   1.2049776e-01 -9.3178499e-01 -2.4142683e-01  1.1472633e+00\n",
      "   3.1381413e-01]\n",
      " [-3.7789969e+00 -2.2111039e+00 -9.3002969e-01 -9.2077273e-01\n",
      "  -8.8559091e-01  1.6303429e-01  5.2402741e-01  4.7712487e-01\n",
      "  -9.7913778e-01]\n",
      " [ 2.6893225e+00  9.4257289e-01  2.5889900e-01 -2.0826466e-01\n",
      "  -6.0983205e-01  4.7582707e-01 -1.5841672e+00 -1.3889171e+00\n",
      "   1.9498370e+00]\n",
      " [ 9.2327852e+00  6.8515247e-01  1.7488031e+00  1.1001562e+00\n",
      "   1.1627243e+00  3.8494182e-01  1.5561980e+00 -3.7273662e+00\n",
      "  -3.9321595e-01]\n",
      " [ 1.0846471e-01 -2.5965919e+00  1.5859291e-02 -8.3400264e-02\n",
      "  -7.7478749e-01 -8.7709969e-01 -8.6529499e-01 -2.7982578e-01\n",
      "   1.6251843e+00]\n",
      " [-2.9061997e+00 -1.1372386e+00 -1.4323211e+00 -6.8952328e-01\n",
      "  -6.0938412e-01 -1.2990884e+00 -5.3587514e-01 -8.6739439e-01\n",
      "   1.7032361e+00]\n",
      " [ 1.4326215e+00  3.5246700e-01 -1.7247680e+00  1.2861563e-01\n",
      "  -9.0861565e-01  3.3585551e-01  2.9510388e+00 -3.2827153e+00\n",
      "   2.9460886e-01]\n",
      " [-2.3606357e-01  1.5965695e+00  6.6535717e-01 -1.8157239e+00\n",
      "  -2.7184817e-01  1.6315742e+00 -2.0200922e+00  2.4920235e+00\n",
      "  -2.7246771e+00]\n",
      " [ 5.0442071e+00  3.5209239e-01 -4.8145351e-01  6.1162806e-01\n",
      "   3.5000604e-01  5.4917753e-01 -1.4248673e+00 -1.0309807e+00\n",
      "   1.0256225e+00]\n",
      " [-2.6387215e+00 -1.3246322e+00 -1.5806015e+00 -5.2716005e-01\n",
      "  -6.0854828e-01  1.2843755e+00 -2.8474700e+00  1.5760944e+00\n",
      "  -9.8096246e-01]\n",
      " [ 2.2046010e+00  1.0881932e+00 -2.3617673e+00 -1.6716219e+00\n",
      "  -1.1435711e+00 -1.5857507e-01 -1.7307773e+00  2.5521961e-01\n",
      "   2.4468215e+00]\n",
      " [-2.1225624e+00 -3.2647140e+00  5.5232346e-01 -1.0048877e+00\n",
      "   1.9974378e-01 -1.2792144e+00  2.4658062e+00 -1.2998120e+00\n",
      "  -1.9853820e-01]\n",
      " [ 4.0618997e+00 -1.5751412e+00  3.1753795e+00  1.9398174e+00\n",
      "   1.8053803e+00  8.4556288e-01 -1.7002873e+00 -1.0563118e+00\n",
      "  -1.3779293e+00]\n",
      " [-1.7443546e+00  1.8396808e+00  1.9091266e+00 -2.6864499e-01\n",
      "   2.1524238e-03 -5.6733114e-01 -2.1764743e+00 -1.3753877e+00\n",
      "   1.2858638e+00]\n",
      " [-4.1351234e+01  5.3989291e+00  4.2278342e+00  2.0333576e+00\n",
      "   6.7699623e-01 -8.9634669e-01  1.0099541e+00  8.3811593e-01\n",
      "  -2.2763428e+01]]>, <Variable path=sequential_55/dense_65/bias, shape=(9,), dtype=float32, value=[ 4.755286   -0.11510872  0.46724138  0.21405497 -0.01656615 -0.15787035\n",
      " -0.35119107  0.38767266 -0.64523464]>]\n"
     ]
    }
   ],
   "source": [
    "single_sample = tf.expand_dims(X_train2[0], axis=0)\n",
    "\n",
    "# Pass it through the model\n",
    "output = model2(single_sample)\n",
    "print(output)\n",
    "print(model2.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       456\n",
      "           1       1.00      1.00      1.00       108\n",
      "\n",
      "    accuracy                           1.00       564\n",
      "   macro avg       1.00      1.00      1.00       564\n",
      "weighted avg       1.00      1.00      1.00       564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_binary = (y_train2 != 0.0).astype(int)\n",
    "\n",
    "# Train-test split\n",
    "X_train_step1, X_test_step1, y_train_step1, y_test_step1 = train_test_split(X_train2, y_train_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression\n",
    "log_reg = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "log_reg.fit(X_train_step1, y_train_step1)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_step1 = log_reg.predict(X_test_step1)\n",
    "print(classification_report(y_test_step1, y_pred_step1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2254, 17)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_step1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_detection(x_input, model):\n",
    "    return model.predict([x_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_step2 = X_train2[y_train != 0]\n",
    "y_train_step2 = y_train[y_train != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2295 - loss: 13.7600 - val_accuracy: 0.4537 - val_loss: 2.5171\n",
      "Epoch 2/20\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2608 - loss: 3.1408 - val_accuracy: 0.4259 - val_loss: 2.2574\n",
      "Epoch 3/20\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3399 - loss: 2.3396 - val_accuracy: 0.2963 - val_loss: 1.8245\n",
      "Epoch 4/20\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3033 - loss: 1.9078 - val_accuracy: 0.4722 - val_loss: 1.7653\n",
      "Epoch 5/20\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3875 - loss: 1.8572 - val_accuracy: 0.4815 - val_loss: 1.6720\n",
      "Epoch 6/20\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3199 - loss: 1.7953 - val_accuracy: 0.5093 - val_loss: 1.8363\n",
      "Epoch 7/20\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3411 - loss: 1.8769 - val_accuracy: 0.4167 - val_loss: 1.7604\n",
      "Epoch 8/20\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3083 - loss: 1.8258 - val_accuracy: 0.5185 - val_loss: 1.8501\n",
      "Epoch 9/20\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3214 - loss: 1.9531 - val_accuracy: 0.5185 - val_loss: 1.9364\n",
      "Epoch 10/20\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3556 - loss: 1.9215 - val_accuracy: 0.5093 - val_loss: 1.6419\n",
      "Epoch 11/20\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4004 - loss: 1.9028 - val_accuracy: 0.3981 - val_loss: 1.7642\n",
      "Epoch 12/20\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3467 - loss: 1.9594 - val_accuracy: 0.4167 - val_loss: 1.6112\n",
      "Epoch 13/20\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4052 - loss: 1.8343 - val_accuracy: 0.3426 - val_loss: 1.6668\n",
      "Epoch 14/20\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3724 - loss: 1.6439 - val_accuracy: 0.3704 - val_loss: 1.6747\n",
      "Epoch 15/20\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3910 - loss: 1.7345 - val_accuracy: 0.3056 - val_loss: 1.9077\n",
      "Epoch 16/20\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2785 - loss: 1.9992 - val_accuracy: 0.5000 - val_loss: 1.8269\n",
      "Epoch 17/20\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3595 - loss: 1.9311 - val_accuracy: 0.5185 - val_loss: 1.8771\n",
      "Epoch 18/20\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3773 - loss: 1.8586 - val_accuracy: 0.4352 - val_loss: 1.6899\n",
      "Epoch 19/20\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3671 - loss: 1.7262 - val_accuracy: 0.3796 - val_loss: 1.7123\n",
      "Epoch 20/20\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3811 - loss: 1.6840 - val_accuracy: 0.2130 - val_loss: 1.8568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 03:03:57.080459: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: Matrix size-incompatible: In[0]: [32,63], In[1]: [17,128]\n",
      "\t [[{{function_node __inference_one_step_on_data_2512221}}{{node sequential_56_1/dense_66_1/Relu}}]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node sequential_56_1/dense_66_1/Relu defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelapp.py\", line 728, in start\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n\n  File \"/var/folders/q0/hn6y49dn3qlbbv0j58dc42tm0000gn/T/ipykernel_39806/4194306141.py\", line 20, in <module>\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 481, in evaluate\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 216, in function\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 129, in multi_step_on_iterator\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 110, in one_step_on_data\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 87, in test_step\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/layer.py\", line 899, in __call__\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/models/sequential.py\", line 213, in call\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/models/functional.py\", line 182, in call\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/ops/function.py\", line 171, in _run_through_graph\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/models/functional.py\", line 632, in call\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/layer.py\", line 899, in __call__\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py\", line 148, in call\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/activations/activations.py\", line 47, in relu\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/activations/activations.py\", line 101, in static_call\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/nn.py\", line 15, in relu\n\nMatrix size-incompatible: In[0]: [32,63], In[1]: [17,128]\n\t [[{{node sequential_56_1/dense_66_1/Relu}}]] [Op:__inference_multi_step_on_iterator_2512246]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[248], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m model\u001b[39m.\u001b[39mfit(X_train_step2, y_train_one_hot, epochs\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, validation_split\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[39m# Evaluate the model\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m model\u001b[39m.\u001b[39;49mevaluate(X_test[y_test \u001b[39m!=\u001b[39;49m \u001b[39m0\u001b[39;49m], y_test_one_hot)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[39m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sequential_56_1/dense_66_1/Relu defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelapp.py\", line 728, in start\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n\n  File \"/Users/liufamily/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n\n  File \"/var/folders/q0/hn6y49dn3qlbbv0j58dc42tm0000gn/T/ipykernel_39806/4194306141.py\", line 20, in <module>\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 481, in evaluate\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 216, in function\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 129, in multi_step_on_iterator\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 110, in one_step_on_data\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 87, in test_step\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/layer.py\", line 899, in __call__\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/models/sequential.py\", line 213, in call\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/models/functional.py\", line 182, in call\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/ops/function.py\", line 171, in _run_through_graph\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/models/functional.py\", line 632, in call\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/layer.py\", line 899, in __call__\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py\", line 148, in call\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/activations/activations.py\", line 47, in relu\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/activations/activations.py\", line 101, in static_call\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend/tensorflow/nn.py\", line 15, in relu\n\nMatrix size-incompatible: In[0]: [32,63], In[1]: [17,128]\n\t [[{{node sequential_56_1/dense_66_1/Relu}}]] [Op:__inference_multi_step_on_iterator_2512246]"
     ]
    }
   ],
   "source": [
    "y_train_one_hot = tf.one_hot(y_train_step2 - 1, depth=8)  # Classes 1-8 become indices 0-7\n",
    "y_test_one_hot = tf.one_hot(y_test[y_test != 0] - 1, depth=8)\n",
    "\n",
    "# Define the neural network\n",
    "input_dim = 17  # Number of features in your input data\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(input_dim,)),  # Input layer with 17 features\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(8, activation='softmax')  # 8 output classes (1-8)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_step2, y_train_one_hot, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(X_test[y_test != 0], y_test_one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_classifier(x_input, anomaly_model, multiclass_models):\n",
    "    # Step 1: Anomaly Detection\n",
    "    is_anomalous = anomaly_detection(x_input, anomaly_model)\n",
    "    if is_anomalous == 0:\n",
    "        return 0  # Class 0\n",
    "\n",
    "    # Step 2: Multiclass Classification (ensemble or pick one)\n",
    "    rf_pred = multiclass_models['rf'].predict([x_input])[0]\n",
    "    svm_pred = multiclass_models['svm'].predict([x_input])[0]\n",
    "    nn_pred = multiclass_models['nn'].predict([x_input]).argmax()\n",
    "\n",
    "    # Combine predictions or use a voting strategy\n",
    "    return rf_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4 (v3.11.4:d2340ef257, Jun  6 2023, 19:15:51) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
